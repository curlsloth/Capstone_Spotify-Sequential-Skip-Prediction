{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ade7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(df_list, ignore_index=True)\n",
    "del df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8d85c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_year</th>\n",
       "      <th>us_popularity_estimate</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>beat_strength</th>\n",
       "      <th>bounciness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>dyn_range_mean</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>acoustic_vector_0</th>\n",
       "      <th>acoustic_vector_1</th>\n",
       "      <th>acoustic_vector_2</th>\n",
       "      <th>acoustic_vector_3</th>\n",
       "      <th>acoustic_vector_4</th>\n",
       "      <th>acoustic_vector_5</th>\n",
       "      <th>acoustic_vector_6</th>\n",
       "      <th>acoustic_vector_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_2e8f4b71-8a0b-4b9c-b7d8-fb5208e87f9f</td>\n",
       "      <td>326.013336</td>\n",
       "      <td>1971</td>\n",
       "      <td>99.582885</td>\n",
       "      <td>0.716209</td>\n",
       "      <td>0.366495</td>\n",
       "      <td>0.332605</td>\n",
       "      <td>0.439835</td>\n",
       "      <td>5.805774</td>\n",
       "      <td>0.238847</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.223395</td>\n",
       "      <td>0.146012</td>\n",
       "      <td>-0.706908</td>\n",
       "      <td>0.259496</td>\n",
       "      <td>0.481157</td>\n",
       "      <td>0.238427</td>\n",
       "      <td>-0.098389</td>\n",
       "      <td>-0.254960</td>\n",
       "      <td>-0.227383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_dae2ec0e-ec7b-4b3e-b60c-4a884d0eccb0</td>\n",
       "      <td>147.813324</td>\n",
       "      <td>1963</td>\n",
       "      <td>97.272035</td>\n",
       "      <td>0.839460</td>\n",
       "      <td>0.362212</td>\n",
       "      <td>0.389829</td>\n",
       "      <td>0.507580</td>\n",
       "      <td>6.845427</td>\n",
       "      <td>0.420476</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>-0.539554</td>\n",
       "      <td>0.105141</td>\n",
       "      <td>0.692589</td>\n",
       "      <td>0.226047</td>\n",
       "      <td>-0.468162</td>\n",
       "      <td>0.164389</td>\n",
       "      <td>-0.769024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_cf0164dd-1531-4399-bfa6-dec19cd1fedc</td>\n",
       "      <td>110.400002</td>\n",
       "      <td>1974</td>\n",
       "      <td>99.620384</td>\n",
       "      <td>0.054673</td>\n",
       "      <td>0.495002</td>\n",
       "      <td>0.589378</td>\n",
       "      <td>0.552311</td>\n",
       "      <td>9.361949</td>\n",
       "      <td>0.842938</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.818441</td>\n",
       "      <td>0.083863</td>\n",
       "      <td>-0.242108</td>\n",
       "      <td>-0.014258</td>\n",
       "      <td>0.096396</td>\n",
       "      <td>0.417641</td>\n",
       "      <td>-0.050576</td>\n",
       "      <td>-0.204757</td>\n",
       "      <td>-0.172563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0f90acc7-d5c5-4e53-901d-55610fbd090c</td>\n",
       "      <td>237.653336</td>\n",
       "      <td>1988</td>\n",
       "      <td>96.796830</td>\n",
       "      <td>0.042606</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.359044</td>\n",
       "      <td>0.585673</td>\n",
       "      <td>6.068578</td>\n",
       "      <td>0.665398</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.594829</td>\n",
       "      <td>0.192498</td>\n",
       "      <td>0.340039</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>-0.389794</td>\n",
       "      <td>0.518381</td>\n",
       "      <td>0.185008</td>\n",
       "      <td>-0.079907</td>\n",
       "      <td>-0.016978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_36b9ad02-095a-443d-a697-6c7285d9410a</td>\n",
       "      <td>174.600006</td>\n",
       "      <td>1987</td>\n",
       "      <td>97.905891</td>\n",
       "      <td>0.249982</td>\n",
       "      <td>0.513640</td>\n",
       "      <td>0.485435</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>7.198735</td>\n",
       "      <td>0.408715</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591289</td>\n",
       "      <td>0.270586</td>\n",
       "      <td>-0.411061</td>\n",
       "      <td>0.165898</td>\n",
       "      <td>0.225652</td>\n",
       "      <td>0.335518</td>\n",
       "      <td>-0.036643</td>\n",
       "      <td>-0.016300</td>\n",
       "      <td>-0.446870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 track_id    duration  release_year  \\\n",
       "0  t_2e8f4b71-8a0b-4b9c-b7d8-fb5208e87f9f  326.013336          1971   \n",
       "1  t_dae2ec0e-ec7b-4b3e-b60c-4a884d0eccb0  147.813324          1963   \n",
       "2  t_cf0164dd-1531-4399-bfa6-dec19cd1fedc  110.400002          1974   \n",
       "3  t_0f90acc7-d5c5-4e53-901d-55610fbd090c  237.653336          1988   \n",
       "4  t_36b9ad02-095a-443d-a697-6c7285d9410a  174.600006          1987   \n",
       "\n",
       "   us_popularity_estimate  acousticness  beat_strength  bounciness  \\\n",
       "0               99.582885      0.716209       0.366495    0.332605   \n",
       "1               97.272035      0.839460       0.362212    0.389829   \n",
       "2               99.620384      0.054673       0.495002    0.589378   \n",
       "3               96.796830      0.042606       0.389634    0.359044   \n",
       "4               97.905891      0.249982       0.513640    0.485435   \n",
       "\n",
       "   danceability  dyn_range_mean    energy  ...  time_signature   valence  \\\n",
       "0      0.439835        5.805774  0.238847  ...               4  0.223395   \n",
       "1      0.507580        6.845427  0.420476  ...               4  0.484702   \n",
       "2      0.552311        9.361949  0.842938  ...               4  0.818441   \n",
       "3      0.585673        6.068578  0.665398  ...               4  0.594829   \n",
       "4      0.635095        7.198735  0.408715  ...               4  0.591289   \n",
       "\n",
       "   acoustic_vector_0  acoustic_vector_1  acoustic_vector_2  acoustic_vector_3  \\\n",
       "0           0.146012          -0.706908           0.259496           0.481157   \n",
       "1           0.039554          -0.539554           0.105141           0.692589   \n",
       "2           0.083863          -0.242108          -0.014258           0.096396   \n",
       "3           0.192498           0.340039           0.034846          -0.389794   \n",
       "4           0.270586          -0.411061           0.165898           0.225652   \n",
       "\n",
       "  acoustic_vector_4  acoustic_vector_5  acoustic_vector_6  acoustic_vector_7  \n",
       "0          0.238427          -0.098389          -0.254960          -0.227383  \n",
       "1          0.226047          -0.468162           0.164389          -0.769024  \n",
       "2          0.417641          -0.050576          -0.204757          -0.172563  \n",
       "3          0.518381           0.185008          -0.079907          -0.016978  \n",
       "4          0.335518          -0.036643          -0.016300          -0.446870  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea74c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = tf_df.merge(pd.read_csv('../data/interim/all_data/mbKMeans100clusters.csv', usecols=['track_id','clus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b0d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_csv('../data/raw/training_set/log_0_20180715_000000000000.csv')\n",
    "log_df = log_df.loc[log_df['session_position']<(log_df['session_length']/2)] # only use the 1st half\n",
    "log_df = pd.get_dummies(log_df, columns=['hist_user_behavior_reason_end', 'hist_user_behavior_reason_start', 'context_type'])\n",
    "\n",
    "tf_df = pd.get_dummies(tf_df, columns=['key','time_signature','mode'])\n",
    "\n",
    "df = log_df.merge(tf_df, left_on = 'track_id_clean', right_on = 'track_id')\n",
    "df.sort_values(by = ['session_id', 'session_position'],inplace = True)\n",
    "\n",
    "bool_col = ['skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_is_shuffle','premium',\n",
    "       'hist_user_behavior_reason_end_backbtn',\n",
    "       'hist_user_behavior_reason_end_clickrow',\n",
    "       'hist_user_behavior_reason_end_endplay',\n",
    "       'hist_user_behavior_reason_end_fwdbtn',\n",
    "       'hist_user_behavior_reason_end_logout',\n",
    "       'hist_user_behavior_reason_end_remote',\n",
    "       'hist_user_behavior_reason_end_trackdone',\n",
    "       'hist_user_behavior_reason_start_appload',\n",
    "       'hist_user_behavior_reason_start_backbtn',\n",
    "       'hist_user_behavior_reason_start_clickrow',\n",
    "       'hist_user_behavior_reason_start_endplay',\n",
    "       'hist_user_behavior_reason_start_fwdbtn',\n",
    "       'hist_user_behavior_reason_start_playbtn',\n",
    "       'hist_user_behavior_reason_start_remote',\n",
    "       'hist_user_behavior_reason_start_trackdone',\n",
    "       'hist_user_behavior_reason_start_trackerror', 'context_type_catalog',\n",
    "       'context_type_charts', 'context_type_editorial_playlist',\n",
    "       'context_type_personalized_playlist', 'context_type_radio',\n",
    "       'context_type_user_collection', \n",
    "       'key_0', 'key_1', 'key_2', 'key_3', 'key_4',\n",
    "       'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10', 'key_11',\n",
    "       'time_signature_0', 'time_signature_1', 'time_signature_3',\n",
    "       'time_signature_4', 'time_signature_5', 'mode_major', 'mode_minor']\n",
    "\n",
    "df[bool_col] = df[bool_col].astype('bool')\n",
    "df.head()\n",
    "del log_df, tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd68d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions import featureAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a568df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from dask.dataframe import from_pandas\n",
    "ddf = from_pandas(df, npartitions=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997e1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "median_fun = dd.Aggregation(\n",
    "    name='median_fun',\n",
    "    chunk=lambda s: s.median(), # this computes the median on each partition\n",
    "    agg=lambda s0: s0.sum() # this combines results across partitions; the input should just be a list of length 1\n",
    ")  \n",
    "\n",
    "iqr_fun = dd.Aggregation(\n",
    "    name='iqr_fun',\n",
    "    chunk=lambda s: s.quantile(.75)-s.quantile(.25), # this computes the median on each partition\n",
    "    agg=lambda s0: s0.sum() # this combines results across partitions; the input should just be a list of length 1\n",
    ")  \n",
    "\n",
    "skew_fun = dd.Aggregation(\n",
    "    name='skew_fun',\n",
    "    chunk=lambda s: s.skew(), # this computes the median on each partition\n",
    "    agg=lambda s0: s0.sum() # this combines results across partitions; the input should just be a list of length 1\n",
    ")\n",
    "\n",
    "range_fun = dd.Aggregation(\n",
    "    name='range_fun',\n",
    "    chunk=lambda s: s.max()-s.min(), # this computes the median on each partition\n",
    "    agg=lambda s0: s0.sum() # this combines results across partitions; the input should just be a list of length 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc522228",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_FA = ['session_position', 'session_length', \n",
    "       'skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hour_of_day', 'premium',\n",
    "       'hist_user_behavior_reason_end_backbtn',\n",
    "       'hist_user_behavior_reason_end_clickrow',\n",
    "       'hist_user_behavior_reason_end_endplay',\n",
    "       'hist_user_behavior_reason_end_fwdbtn',\n",
    "       'hist_user_behavior_reason_end_logout',\n",
    "       'hist_user_behavior_reason_end_remote',\n",
    "       'hist_user_behavior_reason_end_trackdone',\n",
    "       'hist_user_behavior_reason_start_appload',\n",
    "       'hist_user_behavior_reason_start_backbtn',\n",
    "       'hist_user_behavior_reason_start_clickrow',\n",
    "       'hist_user_behavior_reason_start_endplay',\n",
    "       'hist_user_behavior_reason_start_fwdbtn',\n",
    "       'hist_user_behavior_reason_start_playbtn',\n",
    "       'hist_user_behavior_reason_start_remote',\n",
    "       'hist_user_behavior_reason_start_trackdone',\n",
    "       'hist_user_behavior_reason_start_trackerror', 'context_type_catalog',\n",
    "       'context_type_charts', 'context_type_editorial_playlist',\n",
    "       'context_type_personalized_playlist', 'context_type_radio',\n",
    "       'context_type_user_collection', 'duration', 'release_year',\n",
    "       'us_popularity_estimate', 'acousticness', 'beat_strength', 'bounciness',\n",
    "       'danceability', 'dyn_range_mean', 'energy', 'flatness',\n",
    "       'instrumentalness', 'liveness', 'loudness', 'mechanism', 'organism',\n",
    "       'speechiness', 'tempo', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7', 'key_0', 'key_1', 'key_2', 'key_3', 'key_4',\n",
    "       'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10', 'key_11',\n",
    "       'time_signature_0', 'time_signature_1', 'time_signature_3',\n",
    "       'time_signature_4', 'time_signature_5', 'mode_major', 'mode_minor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf7480a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 89.09s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer #to see how long the computation will take\n",
    "start = timer()\n",
    "\n",
    "aa = ddf.groupby(['session_id'])[col_FA].agg(['mean'])\n",
    "\n",
    "print('Runtime: %0.2fs' % (timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776e5c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>session_position</th>\n",
       "      <th>session_length</th>\n",
       "      <th>skip_1</th>\n",
       "      <th>skip_2</th>\n",
       "      <th>skip_3</th>\n",
       "      <th>not_skipped</th>\n",
       "      <th>context_switch</th>\n",
       "      <th>no_pause_before_play</th>\n",
       "      <th>short_pause_before_play</th>\n",
       "      <th>long_pause_before_play</th>\n",
       "      <th>hist_user_behavior_n_seekfwd</th>\n",
       "      <th>hist_user_behavior_n_seekback</th>\n",
       "      <th>hist_user_behavior_is_shuffle</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>premium</th>\n",
       "      <th>hist_user_behavior_reason_end_backbtn</th>\n",
       "      <th>hist_user_behavior_reason_end_clickrow</th>\n",
       "      <th>hist_user_behavior_reason_end_endplay</th>\n",
       "      <th>hist_user_behavior_reason_end_fwdbtn</th>\n",
       "      <th>hist_user_behavior_reason_end_logout</th>\n",
       "      <th>hist_user_behavior_reason_end_remote</th>\n",
       "      <th>hist_user_behavior_reason_end_trackdone</th>\n",
       "      <th>hist_user_behavior_reason_start_appload</th>\n",
       "      <th>hist_user_behavior_reason_start_backbtn</th>\n",
       "      <th>hist_user_behavior_reason_start_clickrow</th>\n",
       "      <th>hist_user_behavior_reason_start_endplay</th>\n",
       "      <th>hist_user_behavior_reason_start_fwdbtn</th>\n",
       "      <th>hist_user_behavior_reason_start_playbtn</th>\n",
       "      <th>hist_user_behavior_reason_start_remote</th>\n",
       "      <th>hist_user_behavior_reason_start_trackdone</th>\n",
       "      <th>hist_user_behavior_reason_start_trackerror</th>\n",
       "      <th>context_type_catalog</th>\n",
       "      <th>context_type_charts</th>\n",
       "      <th>context_type_editorial_playlist</th>\n",
       "      <th>context_type_personalized_playlist</th>\n",
       "      <th>context_type_radio</th>\n",
       "      <th>context_type_user_collection</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_year</th>\n",
       "      <th>us_popularity_estimate</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>beat_strength</th>\n",
       "      <th>bounciness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>dyn_range_mean</th>\n",
       "      <th>energy</th>\n",
       "      <th>flatness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>organism</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>acoustic_vector_0</th>\n",
       "      <th>acoustic_vector_1</th>\n",
       "      <th>acoustic_vector_2</th>\n",
       "      <th>acoustic_vector_3</th>\n",
       "      <th>acoustic_vector_4</th>\n",
       "      <th>acoustic_vector_5</th>\n",
       "      <th>acoustic_vector_6</th>\n",
       "      <th>acoustic_vector_7</th>\n",
       "      <th>key_0</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "      <th>mode_major</th>\n",
       "      <th>mode_minor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: aggregate-agg, 8 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              session_position session_length   skip_1   skip_2   skip_3 not_skipped context_switch no_pause_before_play short_pause_before_play long_pause_before_play hist_user_behavior_n_seekfwd hist_user_behavior_n_seekback hist_user_behavior_is_shuffle hour_of_day  premium hist_user_behavior_reason_end_backbtn hist_user_behavior_reason_end_clickrow hist_user_behavior_reason_end_endplay hist_user_behavior_reason_end_fwdbtn hist_user_behavior_reason_end_logout hist_user_behavior_reason_end_remote hist_user_behavior_reason_end_trackdone hist_user_behavior_reason_start_appload hist_user_behavior_reason_start_backbtn hist_user_behavior_reason_start_clickrow hist_user_behavior_reason_start_endplay hist_user_behavior_reason_start_fwdbtn hist_user_behavior_reason_start_playbtn hist_user_behavior_reason_start_remote hist_user_behavior_reason_start_trackdone hist_user_behavior_reason_start_trackerror context_type_catalog context_type_charts context_type_editorial_playlist context_type_personalized_playlist context_type_radio context_type_user_collection duration release_year us_popularity_estimate acousticness beat_strength bounciness danceability dyn_range_mean   energy flatness instrumentalness liveness loudness mechanism organism speechiness    tempo  valence acoustic_vector_0 acoustic_vector_1 acoustic_vector_2 acoustic_vector_3 acoustic_vector_4 acoustic_vector_5 acoustic_vector_6 acoustic_vector_7    key_0    key_1    key_2    key_3    key_4    key_5    key_6    key_7    key_8    key_9   key_10   key_11 time_signature_0 time_signature_1 time_signature_3 time_signature_4 time_signature_5 mode_major mode_minor\n",
       "                          mean           mean     mean     mean     mean        mean           mean                 mean                    mean                   mean                         mean                          mean                          mean        mean     mean                                  mean                                   mean                                  mean                                 mean                                 mean                                 mean                                    mean                                    mean                                    mean                                     mean                                    mean                                   mean                                    mean                                   mean                                      mean                                       mean                 mean                mean                            mean                               mean               mean                         mean     mean         mean                   mean         mean          mean       mean         mean           mean     mean     mean             mean     mean     mean      mean     mean        mean     mean     mean              mean              mean              mean              mean              mean              mean              mean              mean     mean     mean     mean     mean     mean     mean     mean     mean     mean     mean     mean     mean             mean             mean             mean             mean             mean       mean       mean\n",
       "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                       float64        float64  float64  float64  float64     float64        float64              float64                 float64                float64                      float64                       float64                       float64     float64  float64                               float64                                float64                               float64                              float64                              float64                              float64                                 float64                                 float64                                 float64                                  float64                                 float64                                float64                                 float64                                float64                                   float64                                    float64              float64             float64                         float64                            float64            float64                      float64  float64      float64                float64      float64       float64    float64      float64        float64  float64  float64          float64  float64  float64   float64  float64     float64  float64  float64           float64           float64           float64           float64           float64           float64           float64           float64  float64  float64  float64  float64  float64  float64  float64  float64  float64  float64  float64  float64          float64          float64          float64          float64          float64    float64    float64\n",
       "                           ...            ...      ...      ...      ...         ...            ...                  ...                     ...                    ...                          ...                           ...                           ...         ...      ...                                   ...                                    ...                                   ...                                  ...                                  ...                                  ...                                     ...                                     ...                                     ...                                      ...                                     ...                                    ...                                     ...                                    ...                                       ...                                        ...                  ...                 ...                             ...                                ...                ...                          ...      ...          ...                    ...          ...           ...        ...          ...            ...      ...      ...              ...      ...      ...       ...      ...         ...      ...      ...               ...               ...               ...               ...               ...               ...               ...               ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              ...              ...              ...              ...              ...        ...        ...\n",
       "Dask Name: aggregate-agg, 8 tasks"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3001c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureAugment(df_history, cols):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df_fa = pd.DataFrame()\n",
    "    \n",
    "    # split the data based on skip_2\n",
    "    df_history_T = df_history.loc[df_history['skip_2']==True]\n",
    "    df_history_F = df_history.loc[df_history['skip_2']==False]\n",
    "        \n",
    "    for c in cols:\n",
    "        df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
    "        df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
    "        df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
    "        df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
    "        \n",
    "        df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
    "        df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
    "        df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
    "        df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
    "        \n",
    "        df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
    "        df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
    "        df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
    "        df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
    "        \n",
    "        # correlations\n",
    "        df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "\n",
    "        df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "\n",
    "        df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
    "        \n",
    "        if df_history[c].dtypes.name != 'bool':\n",
    "            df_fa[c+'_max'] = df_history.groupby(['session_id'])[c].max()\n",
    "            df_fa[c+'_min'] = df_history.groupby(['session_id'])[c].min()\n",
    "            df_fa[c+'_range'] = np.subtract(df_fa[c+'_max'], df_fa[c+'_min'], dtype=np.float32)\n",
    "            df_fa[c+'_q25'] = df_history.groupby(['session_id'])[c].quantile(.25)\n",
    "            df_fa[c+'_q75'] = df_history.groupby(['session_id'])[c].quantile(.75)\n",
    "            df_fa[c+'_iqr'] = np.subtract(df_fa[c+'_q75'], df_fa[c+'_q25'], dtype=np.float32)\n",
    "            \n",
    "            df_fa[c+'_T_max'] = df_history_T.groupby(['session_id'])[c].max()\n",
    "            df_fa[c+'_T_min'] = df_history_T.groupby(['session_id'])[c].min()\n",
    "            df_fa[c+'_T_range'] = np.subtract(df_fa[c+'_T_max'], df_fa[c+'_T_min'], dtype=np.float32)\n",
    "            df_fa[c+'_T_q25'] = df_history_T.groupby(['session_id'])[c].quantile(.25)\n",
    "            df_fa[c+'_T_q75'] = df_history_T.groupby(['session_id'])[c].quantile(.75)\n",
    "            df_fa[c+'_T_iqr'] = np.subtract(df_fa[c+'_T_q75'], df_fa[c+'_T_q25'], dtype=np.float32)\n",
    "            \n",
    "            df_fa[c+'_F_max'] = df_history_F.groupby(['session_id'])[c].max()\n",
    "            df_fa[c+'_F_min'] = df_history_F.groupby(['session_id'])[c].min()\n",
    "            df_fa[c+'_F_range'] = np.subtract(df_fa[c+'_F_max'], df_fa[c+'_F_min'], dtype=np.float32)\n",
    "            df_fa[c+'_F_q25'] = df_history_F.groupby(['session_id'])[c].quantile(.25)\n",
    "            df_fa[c+'_F_q75'] = df_history_F.groupby(['session_id'])[c].quantile(.75)\n",
    "            df_fa[c+'_F_iqr'] = np.subtract(df_fa[c+'_F_q75'], df_fa[c+'_F_q25'], dtype=np.float32)\n",
    "            \n",
    "#             df_fa[c+'_mode'] = df_history.groupby(['session_id'])[c].agg(pd.Series.mode)\n",
    "\n",
    "    return df_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a672a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_max'] = df_history.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_min'] = df_history.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_range'] = np.subtract(df_fa[c+'_max'], df_fa[c+'_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q25'] = df_history.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q75'] = df_history.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:225: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_iqr'] = np.subtract(df_fa[c+'_q75'], df_fa[c+'_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:227: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_max'] = df_history_T.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:228: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_min'] = df_history_T.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:229: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_range'] = np.subtract(df_fa[c+'_T_max'], df_fa[c+'_T_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:230: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q25'] = df_history_T.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:231: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q75'] = df_history_T.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_iqr'] = np.subtract(df_fa[c+'_T_q75'], df_fa[c+'_T_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:234: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_max'] = df_history_F.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:235: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_min'] = df_history_F.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_range'] = np.subtract(df_fa[c+'_F_max'], df_fa[c+'_F_min'], dtype=np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:237: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q25'] = df_history_F.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:238: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q75'] = df_history_F.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:239: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_iqr'] = np.subtract(df_fa[c+'_F_q75'], df_fa[c+'_F_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_max'] = df_history.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_min'] = df_history.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_range'] = np.subtract(df_fa[c+'_max'], df_fa[c+'_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q25'] = df_history.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q75'] = df_history.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:225: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_iqr'] = np.subtract(df_fa[c+'_q75'], df_fa[c+'_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:227: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_max'] = df_history_T.groupby(['session_id'])[c].max()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:228: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_min'] = df_history_T.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:229: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_range'] = np.subtract(df_fa[c+'_T_max'], df_fa[c+'_T_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:230: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q25'] = df_history_T.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:231: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q75'] = df_history_T.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_iqr'] = np.subtract(df_fa[c+'_T_q75'], df_fa[c+'_T_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:234: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_max'] = df_history_F.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:235: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_min'] = df_history_F.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_range'] = np.subtract(df_fa[c+'_F_max'], df_fa[c+'_F_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:237: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q25'] = df_history_F.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:238: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q75'] = df_history_F.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:239: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_iqr'] = np.subtract(df_fa[c+'_F_q75'], df_fa[c+'_F_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_max'] = df_history.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_min'] = df_history.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_range'] = np.subtract(df_fa[c+'_max'], df_fa[c+'_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q25'] = df_history.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_q75'] = df_history.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:225: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_iqr'] = np.subtract(df_fa[c+'_q75'], df_fa[c+'_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:227: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_max'] = df_history_T.groupby(['session_id'])[c].max()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:228: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_min'] = df_history_T.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:229: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_range'] = np.subtract(df_fa[c+'_T_max'], df_fa[c+'_T_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:230: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q25'] = df_history_T.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:231: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_q75'] = df_history_T.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_iqr'] = np.subtract(df_fa[c+'_T_q75'], df_fa[c+'_T_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:234: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_max'] = df_history_F.groupby(['session_id'])[c].max()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:235: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_min'] = df_history_F.groupby(['session_id'])[c].min()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_range'] = np.subtract(df_fa[c+'_F_max'], df_fa[c+'_F_min'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:237: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q25'] = df_history_F.groupby(['session_id'])[c].quantile(.25)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:238: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_q75'] = df_history_F.groupby(['session_id'])[c].quantile(.75)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:239: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_iqr'] = np.subtract(df_fa[c+'_F_q75'], df_fa[c+'_F_q25'], dtype=np.float32)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:211: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_PearsonTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_SpearTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_KendallTrend'] = df_history_T.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:215: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_PearsonTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:216: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_SpearTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:217: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_KendallTrend'] = df_history_F.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_mean'] = df_history.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_std'] = df_history.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_skew'] = df_history.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_median'] = df_history.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_mean'] = df_history_T.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_std'] = df_history_T.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_skew'] = df_history_T.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_T_median'] = df_history_T.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:201: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_mean'] = df_history_F.groupby(['session_id'])[c].mean()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_std'] = df_history_F.groupby(['session_id'])[c].std()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:203: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_skew'] = df_history_F.groupby(['session_id'])[c].skew()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_F_median'] = df_history_F.groupby(['session_id'])[c].median()\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_PearsonTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr().iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:208: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fa[c+'_SpearTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('spearman').iloc[0::2,-1].reset_index(level=1, drop=True)\n",
      "/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_fa[c+'_KendallTrend'] = df_history.groupby(['session_id'])[c, 'session_position'].corr('kendall').iloc[0::2,-1].reset_index(level=1, drop=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 40\u001b[0m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      4\u001b[0m col_FA \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot_skipped\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_switch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_pause_before_play\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_pause_before_play\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_signature_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_signature_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_signature_3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     38\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_signature_4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_signature_5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode_major\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode_minor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m df_fa \u001b[38;5;241m=\u001b[39m \u001b[43mfeatureAugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_FA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRuntime: \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (timer() \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[0;32m/Volumes/AC8888/Capstone_Spotify-Sequential-Skip-Prediction/notebooks/functions.py:209\u001b[0m, in \u001b[0;36mfeatureAugment\u001b[0;34m(df_history, cols)\u001b[0m\n\u001b[1;32m    207\u001b[0m df_fa[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_PearsonTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_history\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_position\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m df_fa[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_SpearTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_history\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_position\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 209\u001b[0m df_fa[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_KendallTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession_position\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkendall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    211\u001b[0m df_fa[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_T_PearsonTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_history_T\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_position\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m df_fa[c\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_T_SpearTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_history_T\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_position\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1042\u001b[0m, in \u001b[0;36mGroupBy._make_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_transform \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m-> 1042\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_indexed_same\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdifference(result\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1610\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1612\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1025\u001b[0m, in \u001b[0;36mGroupBy._make_wrapper.<locals>.wrapper.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1023\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default value of numeric_only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, match, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/frame.py:10321\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10319\u001b[0m     c \u001b[38;5;241m=\u001b[39m corrf(ac[valid], bc[valid])\n\u001b[1;32m  10320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 10321\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mcorrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10322\u001b[0m correl[i, j] \u001b[38;5;241m=\u001b[39m c\n\u001b[1;32m  10323\u001b[0m correl[j, i] \u001b[38;5;241m=\u001b[39m c\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/pandas/core/nanops.py:1562\u001b[0m, in \u001b[0;36mget_corr_func.<locals>.func\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(a, b):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkendalltau\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/scipy/stats/_stats_py.py:5131\u001b[0m, in \u001b[0;36mkendalltau\u001b[0;34m(x, y, initial_lexsort, nan_policy, method, variant, alternative)\u001b[0m\n\u001b[1;32m   5128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m KendalltauResult(np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m   5130\u001b[0m \u001b[38;5;66;03m# check both x and y\u001b[39;00m\n\u001b[0;32m-> 5131\u001b[0m cnx, npx \u001b[38;5;241m=\u001b[39m \u001b[43m_contains_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5132\u001b[0m cny, npy \u001b[38;5;241m=\u001b[39m _contains_nan(y, nan_policy)\n\u001b[1;32m   5133\u001b[0m contains_nan \u001b[38;5;241m=\u001b[39m cnx \u001b[38;5;129;01mor\u001b[39;00m cny\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/scipy/stats/_stats_py.py:99\u001b[0m, in \u001b[0;36m_contains_nan\u001b[0;34m(a, nan_policy, use_summation)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_summation:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 99\u001b[0m         contains_nan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     contains_nan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(a)\u001b[38;5;241m.\u001b[39many()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2296\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_DS_2022/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer #to see how long the computation will take\n",
    "start = timer()\n",
    "\n",
    "\n",
    "\n",
    "df_fa = featureAugment(df, col_FA)\n",
    "print('Runtime: %0.2fs' % (timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc628d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
