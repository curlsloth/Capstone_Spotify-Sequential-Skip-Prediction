{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e66449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "tf_df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    tf_df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(tf_df_list, ignore_index=True)\n",
    "tf_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n",
    "kmean300_df = pd.read_csv('../data/interim/all_data/mbKMeans300clusters.csv', usecols=['track_id','clus'])\n",
    "kmean300_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff380d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(df_hist, df_lookup, sim_file_list, score_name_list):\n",
    "    df_hist['ListenYes'] = (df_hist['skip_2'] == False)*1\n",
    "    df_hist['ListenYes'].replace(0, -1, inplace = True)\n",
    "    df_hist = df_hist.groupby(['session_id', 'clus']).agg({'ListenYes':['sum']})\n",
    "    df_hist = df_hist.reset_index()\n",
    "    df_hist.columns = df_hist.columns.droplevel(level = 1) # take out the unwanted level\n",
    "    df_pivot = pd.pivot_table(df_hist, values = 'ListenYes',index='session_id', columns='clus')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    \n",
    "    for sim_file, score_name in zip(sim_file_list, score_name_list):\n",
    "        sim_matrix = pd.read_csv(sim_file).drop(columns=['Unnamed: 0'])\n",
    "        sim_matrix.columns = list(map(str, range(0,len(sim_matrix))))\n",
    "        df_sim_session = df_pivot.dot(sim_matrix)/sim_matrix.sum()\n",
    "        \n",
    "        df_lookup[score_name] = df_sim_session.lookup(df_lookup['session_id'],df_lookup['clus'].astype(str))\n",
    "    \n",
    "    return df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8654cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_FA = ['skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch','hour_of_day','premium',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hist_user_behavior_reason_end_backbtn',\n",
    "       'hist_user_behavior_reason_end_clickrow',\n",
    "       'hist_user_behavior_reason_end_endplay',\n",
    "       'hist_user_behavior_reason_end_fwdbtn',\n",
    "       'hist_user_behavior_reason_end_logout',\n",
    "       'hist_user_behavior_reason_end_remote',\n",
    "       'hist_user_behavior_reason_end_trackdone',\n",
    "       'hist_user_behavior_reason_start_appload',\n",
    "       'hist_user_behavior_reason_start_backbtn',\n",
    "       'hist_user_behavior_reason_start_clickrow',\n",
    "       'hist_user_behavior_reason_start_endplay',\n",
    "       'hist_user_behavior_reason_start_fwdbtn',\n",
    "       'hist_user_behavior_reason_start_playbtn',\n",
    "       'hist_user_behavior_reason_start_remote',\n",
    "       'hist_user_behavior_reason_start_trackdone',\n",
    "       'hist_user_behavior_reason_start_trackerror', 'context_type_catalog',\n",
    "       'context_type_charts', 'context_type_editorial_playlist',\n",
    "       'context_type_personalized_playlist', 'context_type_radio',\n",
    "       'context_type_user_collection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc506af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for n in range(9):\n",
    "    file_list = file_list + glob.glob('../data/raw/training_set/log_'+str(n)+'*.csv')\n",
    "\n",
    "random.shuffle(file_list) # randomly shuffle the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c27f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1247.73s\n",
      "Runtime: 722.71s\n",
      "Runtime: 1136.25s\n",
      "Runtime: 925.72s\n",
      "Runtime: 692.13s\n",
      "Runtime: 970.39s\n",
      "Runtime: 1351.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (learning_rate) > (0.0) at /Users/runner/miniforge3/conda-bld/lightgbm_1666917161455/work/compile/src/io/config_auto.cpp, line 331 .\n",
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (learning_rate) > (0.0) at /Users/runner/miniforge3/conda-bld/lightgbm_1666917161455/work/compile/src/io/config_auto.cpp, line 331 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/bayes_opt/target_space.py:191\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.0, 415.34364599418944, 17.90533596701196)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m lgb_bo\u001b[38;5;241m.\u001b[39msubscribe(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP, logger)\n\u001b[1;32m     71\u001b[0m start \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m---> 72\u001b[0m \u001b[43mlgb_bo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRuntime: \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (timer() \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    303\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    304\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:200\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/bayes_opt/target_space.py:194\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 194\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "Cell \u001b[0;32mIn [7], line 60\u001b[0m, in \u001b[0;36mbo_tune_lgb\u001b[0;34m(num_leaves, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbo_tune_lgb\u001b[39m(num_leaves, learning_rate, num_iterations):\n\u001b[1;32m     51\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(num_leaves),\n\u001b[1;32m     52\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:learning_rate,\n\u001b[1;32m     53\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     59\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m---> 60\u001b[0m     cv_result \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcv_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_error-mean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/lightgbm/engine.py:599\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    596\u001b[0m         params\u001b[38;5;241m.\u001b[39mpop(metric_alias, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    597\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics\n\u001b[0;32m--> 599\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[1;32m    600\u001b[0m          \u001b[38;5;241m.\u001b[39m_set_predictor(predictor) \\\n\u001b[1;32m    601\u001b[0m          \u001b[38;5;241m.\u001b[39mset_feature_name(feature_name) \\\n\u001b[1;32m    602\u001b[0m          \u001b[38;5;241m.\u001b[39mset_categorical_feature(categorical_feature)\n\u001b[1;32m    604\u001b[0m results \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    605\u001b[0m cvfolds \u001b[38;5;241m=\u001b[39m _make_n_folds(train_set, folds\u001b[38;5;241m=\u001b[39mfolds, nfold\u001b[38;5;241m=\u001b[39mnfold,\n\u001b[1;32m    606\u001b[0m                         params\u001b[38;5;241m=\u001b[39mparams, seed\u001b[38;5;241m=\u001b[39mseed, fpreproc\u001b[38;5;241m=\u001b[39mfpreproc,\n\u001b[1;32m    607\u001b[0m                         stratified\u001b[38;5;241m=\u001b[39mstratified, shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m    608\u001b[0m                         eval_train_metric\u001b[38;5;241m=\u001b[39meval_train_metric)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Springboard_new/lib/python3.8/site-packages/lightgbm/basic.py:1934\u001b[0m, in \u001b[0;36mDataset._update_params\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1932\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_free_handle()\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1934\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (learning_rate) > (0.0) at /Users/runner/miniforge3/conda-bld/lightgbm_1666917161455/work/compile/src/io/config_auto.cpp, line 331 .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from timeit import default_timer as timer #to see how long the computation will take\n",
    "\n",
    "nFile = 0\n",
    "batch_size = 20\n",
    "while nFile < len(file_list):\n",
    "    start = timer()\n",
    "    nFile += batch_size\n",
    "    df_lookup_list = []\n",
    "    for file in file_list[(nFile-batch_size):min(nFile, len(file_list))]:\n",
    "\n",
    "        log_df = pd.read_csv(file)\n",
    "        log_df = log_df.merge(kmean300_df)\n",
    "\n",
    "        log_df_1 = log_df.loc[log_df['session_position']<(log_df['session_length']/2)]\n",
    "        log_df_1['hour_of_day'] = log_df_1['hour_of_day'].astype('float')\n",
    "        log_df_1['premium'] = log_df_1['premium'].astype('bool')\n",
    "        log_df_1['weekday'] = log_df_1['date'].astype('datetime64[ns]').dt.dayofweek\n",
    "        log_df_1 = log_df_1.drop(columns = ['date'])\n",
    "        log_df_1 = pd.get_dummies(log_df_1, columns=['hist_user_behavior_reason_end', 'hist_user_behavior_reason_start', 'context_type'])\n",
    "        log_df_1_summary = log_df_1.groupby(['session_id'])[col_FA].agg(['mean'])\n",
    "        log_df_1_summary.columns = log_df_1_summary.columns.get_level_values(0)+'_'+log_df_1_summary.columns.get_level_values(1)\n",
    "        log_df_history = log_df_1[['session_id','track_id_clean','skip_2','clus']]\n",
    "\n",
    "\n",
    "        half_cut = log_df['session_length']/2\n",
    "        \n",
    "        # need to at least include 2 trials, otherwise the log_df_1_summary will confound with all the tracks in the same session\n",
    "\n",
    "        #1st trial in the 2nd half\n",
    "        log_df_2_1 = log_df.loc[(log_df['session_position']>=half_cut) & (log_df['session_position']<half_cut+1)]\n",
    "        log_df_2_1 = log_df_2_1[['session_id','track_id_clean','skip_2','session_position','session_length','clus']]\n",
    "        log_df_2_1['weight'] = 1\n",
    "        \n",
    "        #2nd trial in the 2nd half\n",
    "        log_df_2_2 = log_df.loc[(log_df['session_position']>=half_cut+1) & (log_df['session_position']<half_cut+2)]\n",
    "        log_df_2_2 = log_df_2_2[['session_id','track_id_clean','skip_2','session_position','session_length','clus']]\n",
    "        log_df_2_2['weight'] = 0.5\n",
    "        \n",
    "        log_df_2 = pd.concat([log_df_2_1,log_df_2_2])\n",
    "        log_df_2 = log_df_2.merge(log_df_1_summary, on='session_id')\n",
    "\n",
    "\n",
    "        sim_file_list = ['../models/SVD/similarity/k300_CanbDist.csv',\n",
    "                         '../models/SVD/similarity/k300_CosSim.csv',\n",
    "                         '../models/SVD/similarity/k300_LinCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_ManhDist.csv',\n",
    "                         '../models/SVD/similarity/k300_HammDist.csv',\n",
    "                         '../models/SVD/similarity/k300_SpearCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_KendCorr.csv']\n",
    "        score_name_list = ['CanbDist300', 'CosSim300','LinCorr300','ManhDist300','HammDist300','SpearCorr300','KendCorr300']\n",
    "\n",
    "        df_lookup_list.append(get_sim(log_df_history, log_df_2, sim_file_list, score_name_list))\n",
    "\n",
    "\n",
    "    df_lookup = pd.concat(df_lookup_list)\n",
    "    df_lookup = df_lookup.merge(tf_df)\n",
    "    df_lookup.drop(columns = ['key','time_signature','mode'], inplace = True)\n",
    "#     df_lookup = pd.get_dummies(df_lookup, columns=['key','time_signature','mode'])\n",
    "\n",
    "    dtrain = lgb.Dataset(df_lookup.drop(columns = ['session_id','track_id_clean','skip_2']), \n",
    "                         label=df_lookup['skip_2'],\n",
    "                         weight = df_lookup['weight'])\n",
    "\n",
    "    def bo_tune_lgb(num_leaves, learning_rate, num_iterations):\n",
    "        params = {'num_leaves': int(num_leaves),\n",
    "                  'learning_rate':learning_rate,\n",
    "                  'metric': 'binary_error',\n",
    "                  'num_iterations':int(num_iterations),\n",
    "                  'early_stopping_round':5,\n",
    "                  'objective': 'binary',\n",
    "                  'force_row_wise': True,\n",
    "                  'num_threads': 5,\n",
    "                  'verbosity': 0}\n",
    "        cv_result = lgb.cv(params, dtrain, nfold=4)\n",
    "        return 1-cv_result['binary_error-mean'][-1]\n",
    "\n",
    "    lgb_bo = BayesianOptimization(bo_tune_lgb, {'num_leaves': (5, 40),\n",
    "                                                'learning_rate':(0.001,0.5),\n",
    "                                                'num_iterations': (10,1000)\n",
    "                                                })\n",
    "\n",
    "    logger = JSONLogger(path='../models/SVD/LightGBM_BayesOpt/logs_shuffle'+str(nFile)+'.json')\n",
    "    lgb_bo.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "\n",
    "    start = timer()\n",
    "    lgb_bo.maximize(n_iter=10, init_points=10)\n",
    "    print('Runtime: %0.2fs' % (timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f0bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af837e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
