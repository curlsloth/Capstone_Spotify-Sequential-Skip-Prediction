{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa4f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(df_list, ignore_index=True)\n",
    "tf_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n",
    "\n",
    "file_list = glob.glob('../data/raw/training_set/log_0*.csv')\n",
    "log_df = dd.read_csv(file_list)\n",
    "# log_df = pd.read_csv('../data/raw/training_set/log_0_20180715_000000000000.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601028df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(df_hist, df_lookup, sim_file_list, score_name_list):\n",
    "    df_hist['ListenYes'] = (df_hist['skip_2'] == False)*1\n",
    "    df_hist['ListenYes'].replace(0, -1, inplace = True)\n",
    "    df_hist = df_hist.groupby(['session_id', 'clus']).agg({'ListenYes':['sum']})\n",
    "    df_hist = df_hist.reset_index()\n",
    "    df_hist.columns = df_hist.columns.droplevel(level = 1) # take out the unwanted level\n",
    "    df_pivot = pd.pivot_table(df_hist, values = 'ListenYes',index='session_id', columns='clus')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    \n",
    "    for sim_file, score_name in zip(sim_file_list, score_name_list):\n",
    "        sim_matrix = pd.read_csv(sim_file).drop(columns=['Unnamed: 0'])\n",
    "        sim_matrix.columns = list(map(str, range(0,len(sim_matrix))))\n",
    "        df_sim_session = df_pivot.dot(sim_matrix)/sim_matrix.sum()\n",
    "        \n",
    "        df_lookup[score_name] = df_sim_session.lookup(df_lookup['session_id'],df_lookup['clus'].astype(str))\n",
    "    \n",
    "    return df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean100_df = pd.read_csv('../data/interim/all_data/mbKMeans100clusters.csv', usecols=['track_id','clus'])\n",
    "kmean100_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "log_df = log_df[['session_id','track_id_clean','skip_2','session_position','session_length']].merge(kmean100_df)\n",
    "\n",
    "log_df_1 = log_df.loc[log_df['session_position']<(log_df['session_length']/2)].compute()\n",
    "\n",
    "# as the entire dataset will be too big to train, \n",
    "# train the first 2 tracks of the 2nd half (prediction set) should be enough, \n",
    "# as these 2 contribute most to the spotify metric\n",
    "\n",
    "half_cut = log_df['session_length']/2\n",
    "\n",
    "log_df_2_1 = log_df.loc[(log_df['session_position']>=half_cut) & (log_df['session_position']<half_cut+1)]\n",
    "log_df_2_1['weight'] = 2\n",
    "log_df_2_2 = log_df.loc[(log_df['session_position']>=half_cut+1) & (log_df['session_position']<half_cut+2)]\n",
    "log_df_2_2['weight'] = 1\n",
    "                                       \n",
    "# log_df_2 = pd.concat([log_df_2_1, log_df_2_2])\n",
    "log_df_2 = dd.concat([log_df_2_1, log_df_2_2]).compute()\n",
    "\n",
    "\n",
    "sim_file_list = ['../models/SVD/similarity/k100_CanbDist.csv',\n",
    "                 '../models/SVD/similarity/k100_CosSim.csv',\n",
    "                 '../models/SVD/similarity/k100_LinCorr.csv',\n",
    "                 '../models/SVD/similarity/k100_ManhDist.csv',\n",
    "                 '../models/SVD/similarity/k100_HammDist.csv',\n",
    "                 '../models/SVD/similarity/k100_SpearCorr.csv',\n",
    "                 '../models/SVD/similarity/k100_KendCorr.csv']\n",
    "score_name_list = ['CanbDist100', 'CosSim100','LinCorr100','ManhDist100','HammDist100','SpearCorr100','KendCorr100']\n",
    "\n",
    "df_lookup = get_sim(log_df_1, log_df_2, sim_file_list, score_name_list)\n",
    "\n",
    "df_lookup = df_lookup.merge(tf_df)\n",
    "df_lookup = pd.get_dummies(df_lookup, columns=['key','time_signature','mode'])\n",
    "\n",
    "dtrain = xgb.DMatrix(df_lookup.drop(columns = ['session_id','track_id_clean','skip_2']), \n",
    "                     label=df_lookup['skip_2'],\n",
    "                     weight = df_lookup['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "150fb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 3,\n",
    "              'gamma': 0.5,\n",
    "              'learning_rate':0.01,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'error'}\n",
    "cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56b00c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33189355031779444"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result['test-error-mean'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ac1de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.6632   \u001b[0m | \u001b[0m0.9008   \u001b[0m | \u001b[0m0.0002473\u001b[0m | \u001b[0m4.137    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.6632   \u001b[0m | \u001b[95m0.2555   \u001b[0m | \u001b[95m0.002755 \u001b[0m | \u001b[95m4.43     \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6644   \u001b[0m | \u001b[95m0.05842  \u001b[0m | \u001b[95m0.007041 \u001b[0m | \u001b[95m5.593    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.667    \u001b[0m | \u001b[95m0.3743   \u001b[0m | \u001b[95m0.005592 \u001b[0m | \u001b[95m8.79     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6664   \u001b[0m | \u001b[0m0.7489   \u001b[0m | \u001b[0m0.002916 \u001b[0m | \u001b[0m6.849    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6666   \u001b[0m | \u001b[0m0.09849  \u001b[0m | \u001b[0m0.002702 \u001b[0m | \u001b[0m7.371    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6664   \u001b[0m | \u001b[0m0.1743   \u001b[0m | \u001b[0m0.005325 \u001b[0m | \u001b[0m6.672    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.667    \u001b[0m | \u001b[0m0.8666   \u001b[0m | \u001b[0m0.003208 \u001b[0m | \u001b[0m9.669    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6664   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m10.0     \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.667    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.005006 \u001b[0m | \u001b[0m8.81     \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6669   \u001b[0m | \u001b[0m0.7101   \u001b[0m | \u001b[0m0.001927 \u001b[0m | \u001b[0m9.15     \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6669   \u001b[0m | \u001b[0m0.9838   \u001b[0m | \u001b[0m0.009493 \u001b[0m | \u001b[0m9.987    \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m0.667    \u001b[0m | \u001b[95m0.59     \u001b[0m | \u001b[95m0.009418 \u001b[0m | \u001b[95m8.349    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "def bo_tune_xgb(max_depth, gamma ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'error'}\n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=10, nfold=5)\n",
    "    #Return the negative RMSE\n",
    "    return 1-cv_result['test-error-mean'].iloc[-1]\n",
    "\n",
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                             'learning_rate':(0,0.01)\n",
    "                                            })\n",
    "xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52697aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5899964093512567,\n",
       " 'learning_rate': 0.009417981929522201,\n",
       " 'max_depth': 8.34871018871217}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b41eef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 8,\n",
    "              'gamma': 0.5899964093512567,\n",
    "              'learning_rate':0.009417981929522201,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'error'}\n",
    "cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d055c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330065</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.336290</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327947</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.335058</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327521</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.327208</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.334010</td>\n",
       "      <td>0.001586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326928</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.333675</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.324187</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.332452</td>\n",
       "      <td>0.001705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.324150</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.324103</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.332460</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.324076</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.332460</td>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.324031</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.332406</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0           0.330065         0.000556         0.336290        0.001781\n",
       "1           0.327947         0.000455         0.335058        0.001734\n",
       "2           0.327521         0.000556         0.334215        0.001634\n",
       "3           0.327208         0.000382         0.334010        0.001586\n",
       "4           0.326928         0.000401         0.333675        0.001769\n",
       "..               ...              ...              ...             ...\n",
       "65          0.324187         0.000580         0.332452        0.001705\n",
       "66          0.324150         0.000591         0.332451        0.001782\n",
       "67          0.324103         0.000569         0.332460        0.001714\n",
       "68          0.324076         0.000612         0.332460        0.001717\n",
       "69          0.324031         0.000619         0.332406        0.001834\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb583ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
