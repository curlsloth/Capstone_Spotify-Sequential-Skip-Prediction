{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e66449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(df_list, ignore_index=True)\n",
    "tf_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n",
    "kmean100_df = pd.read_csv('../data/interim/all_data/mbKMeans100clusters.csv', usecols=['track_id','clus'])\n",
    "kmean100_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff380d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(df_hist, df_lookup, sim_file_list, score_name_list):\n",
    "    df_hist['ListenYes'] = (df_hist['skip_2'] == False)*1\n",
    "    df_hist['ListenYes'].replace(0, -1, inplace = True)\n",
    "    df_hist = df_hist.groupby(['session_id', 'clus']).agg({'ListenYes':['sum']})\n",
    "    df_hist = df_hist.reset_index()\n",
    "    df_hist.columns = df_hist.columns.droplevel(level = 1) # take out the unwanted level\n",
    "    df_pivot = pd.pivot_table(df_hist, values = 'ListenYes',index='session_id', columns='clus')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    \n",
    "    for sim_file, score_name in zip(sim_file_list, score_name_list):\n",
    "        sim_matrix = pd.read_csv(sim_file).drop(columns=['Unnamed: 0'])\n",
    "        sim_matrix.columns = list(map(str, range(0,len(sim_matrix))))\n",
    "        df_sim_session = df_pivot.dot(sim_matrix)/sim_matrix.sum()\n",
    "        \n",
    "        df_lookup[score_name] = df_sim_session.lookup(df_lookup['session_id'],df_lookup['clus'].astype(str))\n",
    "    \n",
    "    return df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbde35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/training_set/log_0_20180722_000000000000.csv\n",
      "../data/raw/training_set/log_0_20180821_000000000000.csv\n",
      "../data/raw/training_set/log_0_20180918_000000000000.csv\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob('../data/raw/training_set/log_0*.csv')\n",
    "df_lookup_list = []\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    log_df = pd.read_csv(file)\n",
    "\n",
    "    log_df = log_df[['session_id','track_id_clean','skip_2','session_position','session_length']].merge(kmean100_df)\n",
    "\n",
    "    log_df_1 = log_df.loc[log_df['session_position']<(log_df['session_length']/2)]\n",
    "\n",
    "    # as the entire dataset will be too big to train, \n",
    "    # train the first 2 tracks of the 2nd half (prediction set) should be enough, \n",
    "    # as these 2 contribute most to the spotify metric\n",
    "\n",
    "    half_cut = log_df['session_length']/2\n",
    "\n",
    "    log_df_2_1 = log_df.loc[(log_df['session_position']>=half_cut) & (log_df['session_position']<half_cut+1)]\n",
    "    log_df_2_1['weight'] = 2\n",
    "    log_df_2_2 = log_df.loc[(log_df['session_position']>=half_cut+1) & (log_df['session_position']<half_cut+2)]\n",
    "    log_df_2_2['weight'] = 1\n",
    "\n",
    "    log_df_2 = pd.concat([log_df_2_1, log_df_2_2])\n",
    "\n",
    "\n",
    "    sim_file_list = ['../models/SVD/similarity/k100_CanbDist.csv',\n",
    "                     '../models/SVD/similarity/k100_CosSim.csv',\n",
    "                     '../models/SVD/similarity/k100_LinCorr.csv',\n",
    "                     '../models/SVD/similarity/k100_ManhDist.csv',\n",
    "                     '../models/SVD/similarity/k100_HammDist.csv',\n",
    "                     '../models/SVD/similarity/k100_SpearCorr.csv',\n",
    "                     '../models/SVD/similarity/k100_KendCorr.csv']\n",
    "    score_name_list = ['CanbDist100', 'CosSim100','LinCorr100','ManhDist100','HammDist100','SpearCorr100','KendCorr100']\n",
    "\n",
    "    df_lookup_list.append(get_sim(log_df_1, log_df_2, sim_file_list, score_name_list))\n",
    "    \n",
    "\n",
    "df_lookup = pd.concat(df_lookup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = df_lookup.merge(tf_df)\n",
    "df_lookup = pd.get_dummies(df_lookup, columns=['key','time_signature','mode'])\n",
    "\n",
    "dtrain = xgb.DMatrix(df_lookup.drop(columns = ['session_id','track_id_clean','skip_2']), \n",
    "                     label=df_lookup['skip_2'],\n",
    "                     weight = df_lookup['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d714301",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BayesianOptimization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcv_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-error-mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Invoking the Bayesian Optimizer with the specified parameters to tune\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m xgb_bo \u001b[38;5;241m=\u001b[39m \u001b[43mBayesianOptimization\u001b[49m(bo_tune_xgb, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     15\u001b[0m                                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     16\u001b[0m                                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     17\u001b[0m                                             })\n\u001b[1;32m     18\u001b[0m xgb_bo\u001b[38;5;241m.\u001b[39mmaximize(n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, acq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mei\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BayesianOptimization' is not defined"
     ]
    }
   ],
   "source": [
    "def bo_tune_xgb(max_depth, gamma ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'error'}\n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=10, nfold=5)\n",
    "    #Return the negative RMSE\n",
    "    return 1-cv_result['test-error-mean'].iloc[-1]\n",
    "\n",
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                             'learning_rate':(0,0.01)\n",
    "                                            })\n",
    "xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ed96d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 8,\n",
    "              'gamma': 0.5899964093512567,\n",
    "              'learning_rate':0.009417981929522201,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'error'}\n",
    "cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df41ba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330065</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.336290</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327947</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.335058</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327521</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.327208</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.334010</td>\n",
       "      <td>0.001586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326928</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.333675</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.324187</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.332452</td>\n",
       "      <td>0.001705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.324150</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.324103</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.332460</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.324076</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.332460</td>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.324031</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.332406</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0           0.330065         0.000556         0.336290        0.001781\n",
       "1           0.327947         0.000455         0.335058        0.001734\n",
       "2           0.327521         0.000556         0.334215        0.001634\n",
       "3           0.327208         0.000382         0.334010        0.001586\n",
       "4           0.326928         0.000401         0.333675        0.001769\n",
       "..               ...              ...              ...             ...\n",
       "65          0.324187         0.000580         0.332452        0.001705\n",
       "66          0.324150         0.000591         0.332451        0.001782\n",
       "67          0.324103         0.000569         0.332460        0.001714\n",
       "68          0.324076         0.000612         0.332460        0.001717\n",
       "69          0.324031         0.000619         0.332406        0.001834\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af837e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
