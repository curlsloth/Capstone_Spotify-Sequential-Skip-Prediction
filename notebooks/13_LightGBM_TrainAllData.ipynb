{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e66449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "tf_df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    tf_df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(tf_df_list, ignore_index=True)\n",
    "tf_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n",
    "kmean300_df = pd.read_csv('../data/interim/all_data/mbKMeans300clusters.csv', usecols=['track_id','clus'])\n",
    "kmean300_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bb2ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>datetime</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>num_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.681502</td>\n",
       "      <td>{'datetime': '2022-12-07 23:44:47', 'elapsed':...</td>\n",
       "      <td>0.358113</td>\n",
       "      <td>289.131177</td>\n",
       "      <td>26.084380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.681493</td>\n",
       "      <td>{'datetime': '2022-12-07 23:45:47', 'elapsed':...</td>\n",
       "      <td>0.133303</td>\n",
       "      <td>207.760447</td>\n",
       "      <td>33.150367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.681441</td>\n",
       "      <td>{'datetime': '2022-12-07 23:52:21', 'elapsed':...</td>\n",
       "      <td>0.254124</td>\n",
       "      <td>290.196840</td>\n",
       "      <td>26.016096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.681438</td>\n",
       "      <td>{'datetime': '2022-12-07 23:51:02', 'elapsed':...</td>\n",
       "      <td>0.078170</td>\n",
       "      <td>206.492684</td>\n",
       "      <td>34.384655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.681308</td>\n",
       "      <td>{'datetime': '2022-12-07 23:48:25', 'elapsed':...</td>\n",
       "      <td>0.288358</td>\n",
       "      <td>193.105700</td>\n",
       "      <td>28.048837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.678831</td>\n",
       "      <td>{'datetime': '2022-12-08 00:07:41', 'elapsed':...</td>\n",
       "      <td>0.893276</td>\n",
       "      <td>382.369298</td>\n",
       "      <td>29.126509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.678700</td>\n",
       "      <td>{'datetime': '2022-12-08 00:02:54', 'elapsed':...</td>\n",
       "      <td>0.996263</td>\n",
       "      <td>99.691578</td>\n",
       "      <td>36.570915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.678698</td>\n",
       "      <td>{'datetime': '2022-12-08 00:08:00', 'elapsed':...</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>60.654934</td>\n",
       "      <td>6.889188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.678485</td>\n",
       "      <td>{'datetime': '2022-12-08 00:04:55', 'elapsed':...</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>479.653026</td>\n",
       "      <td>6.649225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.541545</td>\n",
       "      <td>{'datetime': '2022-12-08 00:33:45', 'elapsed':...</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>63.570941</td>\n",
       "      <td>29.808482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                           datetime  \\\n",
       "34  0.681502  {'datetime': '2022-12-07 23:44:47', 'elapsed':...   \n",
       "35  0.681493  {'datetime': '2022-12-07 23:45:47', 'elapsed':...   \n",
       "48  0.681441  {'datetime': '2022-12-07 23:52:21', 'elapsed':...   \n",
       "45  0.681438  {'datetime': '2022-12-07 23:51:02', 'elapsed':...   \n",
       "41  0.681308  {'datetime': '2022-12-07 23:48:25', 'elapsed':...   \n",
       "..       ...                                                ...   \n",
       "62  0.678831  {'datetime': '2022-12-08 00:07:41', 'elapsed':...   \n",
       "54  0.678700  {'datetime': '2022-12-08 00:02:54', 'elapsed':...   \n",
       "63  0.678698  {'datetime': '2022-12-08 00:08:00', 'elapsed':...   \n",
       "58  0.678485  {'datetime': '2022-12-08 00:04:55', 'elapsed':...   \n",
       "21  0.541545  {'datetime': '2022-12-08 00:33:45', 'elapsed':...   \n",
       "\n",
       "    learning_rate  num_iterations  num_leaves  \n",
       "34       0.358113      289.131177   26.084380  \n",
       "35       0.133303      207.760447   33.150367  \n",
       "48       0.254124      290.196840   26.016096  \n",
       "45       0.078170      206.492684   34.384655  \n",
       "41       0.288358      193.105700   28.048837  \n",
       "..            ...             ...         ...  \n",
       "62       0.893276      382.369298   29.126509  \n",
       "54       0.996263       99.691578   36.570915  \n",
       "63       0.527956       60.654934    6.889188  \n",
       "58       0.095424      479.653026    6.649225  \n",
       "21       0.003648       63.570941   29.808482  \n",
       "\n",
       "[73 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "list_bayesOpt = glob.glob('../models/SVD/LightGBM_BayesOpt/logs_shuffle*.json')\n",
    "\n",
    "optList = []\n",
    "for jsonFile in list_bayesOpt:\n",
    "    with open(jsonFile) as f:\n",
    "        for jsonObj in f:\n",
    "            optDict = json.loads(jsonObj)\n",
    "            optList.append(optDict)\n",
    "\n",
    "\n",
    "opt_df = pd.DataFrame(optList)\n",
    "opt_df = pd.concat([opt_df.drop(['params'], axis=1), opt_df['params'].apply(pd.Series)], axis=1)\n",
    "opt_df.sort_values('target',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff380d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(df_hist, df_lookup, sim_file_list, score_name_list):\n",
    "    df_hist['ListenYes'] = (df_hist['skip_2'] == False)*1\n",
    "    df_hist['ListenYes'].replace(0, -1, inplace = True)\n",
    "    df_hist = df_hist.groupby(['session_id', 'clus']).agg({'ListenYes':['sum']})\n",
    "    df_hist = df_hist.reset_index()\n",
    "    df_hist.columns = df_hist.columns.droplevel(level = 1) # take out the unwanted level\n",
    "    df_pivot = pd.pivot_table(df_hist, values = 'ListenYes',index='session_id', columns='clus')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    \n",
    "    for sim_file, score_name in zip(sim_file_list, score_name_list):\n",
    "        sim_matrix = pd.read_csv(sim_file).drop(columns=['Unnamed: 0'])\n",
    "        sim_matrix.columns = list(map(str, range(0,len(sim_matrix))))\n",
    "        df_sim_session = df_pivot.dot(sim_matrix)/sim_matrix.sum()\n",
    "        \n",
    "        df_lookup[score_name] = df_sim_session.lookup(df_lookup['session_id'],df_lookup['clus'].astype(str))\n",
    "    \n",
    "    return df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc506af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for n in range(9):\n",
    "    file_list = file_list + glob.glob('../data/raw/training_set/log_'+str(n)+'*.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bbde35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_lookup_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m     sim_file_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/SVD/similarity/k300_CanbDist.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/SVD/similarity/k300_CosSim.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/SVD/similarity/k300_LinCorr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/SVD/similarity/k300_SpearCorr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/SVD/similarity/k300_KendCorr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m     score_name_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanbDist300\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCosSim300\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinCorr300\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mManhDist300\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHammDist300\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpearCorr300\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKendCorr300\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mdf_lookup_list\u001b[49m\u001b[38;5;241m.\u001b[39mappend(get_sim(log_df_1, log_df_2, sim_file_list, score_name_list))\n\u001b[1;32m     37\u001b[0m df_lookup \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_lookup_list)\n\u001b[1;32m     38\u001b[0m df_lookup \u001b[38;5;241m=\u001b[39m df_lookup\u001b[38;5;241m.\u001b[39mmerge(tf_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_lookup_list' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from timeit import default_timer as timer #to see how long the computation will take\n",
    "\n",
    "nFile = 0\n",
    "batch_size = 20\n",
    "while nFile < len(file_list):\n",
    "    nFile += batch_size\n",
    "    df_lookup_list = []\n",
    "    for file in file_list[(nFile-batch_size):min(nFile, len(file_list))]:\n",
    "        \n",
    "        start = timer()\n",
    "        \n",
    "        log_df = pd.read_csv(file)\n",
    "\n",
    "        log_df = log_df[['session_id','track_id_clean','skip_2','session_position','session_length','hour_of_day','premium']].merge(kmean300_df)\n",
    "        log_df['hour_of_day'] = log_df['hour_of_day'].astype('float')\n",
    "        log_df['premium'] = log_df['premium'].astype('bool')\n",
    "        log_df_1 = log_df.loc[log_df['session_position']<(log_df['session_length']/2)]\n",
    "\n",
    "        half_cut = log_df['session_length']/2\n",
    "\n",
    "        log_df_2 = log_df.loc[(log_df['session_position']>=half_cut) & (log_df['session_position']<half_cut+1)]\n",
    "        log_df_2['weight'] = 1\n",
    "\n",
    "\n",
    "        sim_file_list = ['../models/SVD/similarity/k300_CanbDist.csv',\n",
    "                         '../models/SVD/similarity/k300_CosSim.csv',\n",
    "                         '../models/SVD/similarity/k300_LinCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_ManhDist.csv',\n",
    "                         '../models/SVD/similarity/k300_HammDist.csv',\n",
    "                         '../models/SVD/similarity/k300_SpearCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_KendCorr.csv']\n",
    "        score_name_list = ['CanbDist300', 'CosSim300','LinCorr300','ManhDist300','HammDist300','SpearCorr300','KendCorr300']\n",
    "\n",
    "        df_lookup_list.append(get_sim(log_df_1, log_df_2, sim_file_list, score_name_list))\n",
    "\n",
    "\n",
    "    df_lookup = pd.concat(df_lookup_list)\n",
    "    df_lookup = df_lookup.merge(tf_df)\n",
    "    df_lookup = pd.get_dummies(df_lookup, columns=['key','time_signature','mode'])\n",
    "\n",
    "    dtrain = lgb.Dataset(df_lookup.drop(columns = ['session_id','track_id_clean','skip_2']), \n",
    "                         label=df_lookup['skip_2'],\n",
    "                         weight = df_lookup['weight'])\n",
    "    \n",
    "    params = {'num_leaves': 26,\n",
    "                  'learning_rate':0.358,\n",
    "                  'metric': 'binary_error',\n",
    "                  'num_iterations':290,\n",
    "                  'early_stopping_round':5,\n",
    "                  'objective': 'binary',\n",
    "                  'force_row_wise': True,\n",
    "                  'num_threads': 5,\n",
    "                  'verbosity': 0}\n",
    "    \n",
    "    if nFile == 20:\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=100)\n",
    "    else:\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=100, init_model='../models/SVD/LightGBM_BayesOpt/LightGBM_incremental_training/boost'+str(nFile-batch_size)+'.txt')\n",
    "        \n",
    "    bst.save_model(path='../models/SVD/LightGBM_BayesOpt/LightGBM_incremental_training/boost'+str(nFile)+'.txt')\n",
    "\n",
    "    print('Runtime per batch: %0.2fs' % (timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2792e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af837e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
