{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e66449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import io\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open('../data/raw/20181120_track_features.tar.gz', 'r:gz')\n",
    "csv_files = tar.getnames()\n",
    "\n",
    "tf_df_list = []\n",
    "\n",
    "for csv_file in [csv_files[2], csv_files[4]]:\n",
    "    csv_contents = tar.extractfile(csv_file).read()\n",
    "    tf_df_list.append(pd.read_csv(io.BytesIO(csv_contents), encoding='utf8'))\n",
    "\n",
    "tf_df = pd.concat(tf_df_list, ignore_index=True)\n",
    "tf_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n",
    "kmean300_df = pd.read_csv('../data/interim/all_data/mbKMeans300clusters.csv', usecols=['track_id','clus'])\n",
    "kmean300_df.rename(columns={'track_id':'track_id_clean'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510bbb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>datetime</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>nFile</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>num_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.740106</td>\n",
       "      <td>{'datetime': '2022-12-09 21:35:53', 'elapsed':...</td>\n",
       "      <td>0.808382</td>\n",
       "      <td>3.260206</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.045185</td>\n",
       "      <td>40.0</td>\n",
       "      <td>438.263273</td>\n",
       "      <td>45.704734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.740106</td>\n",
       "      <td>{'datetime': '2022-12-09 21:15:21', 'elapsed':...</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>1.994299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>40.0</td>\n",
       "      <td>479.436874</td>\n",
       "      <td>37.916497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.740093</td>\n",
       "      <td>{'datetime': '2022-12-10 00:08:06', 'elapsed':...</td>\n",
       "      <td>0.883442</td>\n",
       "      <td>9.491606</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>90.0</td>\n",
       "      <td>219.284683</td>\n",
       "      <td>93.503262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.740057</td>\n",
       "      <td>{'datetime': '2022-12-10 00:19:16', 'elapsed':...</td>\n",
       "      <td>0.317533</td>\n",
       "      <td>5.362842</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.079636</td>\n",
       "      <td>90.0</td>\n",
       "      <td>229.715740</td>\n",
       "      <td>96.115682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.739845</td>\n",
       "      <td>{'datetime': '2022-12-09 22:12:22', 'elapsed':...</td>\n",
       "      <td>0.882175</td>\n",
       "      <td>2.103547</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.049750</td>\n",
       "      <td>50.0</td>\n",
       "      <td>422.996505</td>\n",
       "      <td>62.278690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.739820</td>\n",
       "      <td>{'datetime': '2022-12-09 21:56:38', 'elapsed':...</td>\n",
       "      <td>0.702082</td>\n",
       "      <td>1.710437</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.088671</td>\n",
       "      <td>50.0</td>\n",
       "      <td>442.575021</td>\n",
       "      <td>46.245643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739717</td>\n",
       "      <td>{'datetime': '2022-12-10 00:24:55', 'elapsed':...</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>9.522663</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.028957</td>\n",
       "      <td>100.0</td>\n",
       "      <td>717.599877</td>\n",
       "      <td>20.878224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.739596</td>\n",
       "      <td>{'datetime': '2022-12-09 23:23:16', 'elapsed':...</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>1.994299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>80.0</td>\n",
       "      <td>479.436874</td>\n",
       "      <td>37.916497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.739565</td>\n",
       "      <td>{'datetime': '2022-12-09 20:34:26', 'elapsed':...</td>\n",
       "      <td>0.834545</td>\n",
       "      <td>9.822706</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.067652</td>\n",
       "      <td>20.0</td>\n",
       "      <td>484.308256</td>\n",
       "      <td>89.495379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.739562</td>\n",
       "      <td>{'datetime': '2022-12-09 23:45:58', 'elapsed':...</td>\n",
       "      <td>0.976386</td>\n",
       "      <td>1.522631</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>80.0</td>\n",
       "      <td>715.380881</td>\n",
       "      <td>56.672997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.739497</td>\n",
       "      <td>{'datetime': '2022-12-09 22:35:15', 'elapsed':...</td>\n",
       "      <td>0.955275</td>\n",
       "      <td>2.466394</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.080818</td>\n",
       "      <td>60.0</td>\n",
       "      <td>413.954070</td>\n",
       "      <td>60.979275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.739453</td>\n",
       "      <td>{'datetime': '2022-12-09 23:03:07', 'elapsed':...</td>\n",
       "      <td>0.959201</td>\n",
       "      <td>8.949202</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>70.0</td>\n",
       "      <td>853.416132</td>\n",
       "      <td>62.844482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.739453</td>\n",
       "      <td>{'datetime': '2022-12-09 20:29:01', 'elapsed':...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>485.337529</td>\n",
       "      <td>49.965982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.739435</td>\n",
       "      <td>{'datetime': '2022-12-09 21:03:30', 'elapsed':...</td>\n",
       "      <td>0.922832</td>\n",
       "      <td>1.445393</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.080182</td>\n",
       "      <td>30.0</td>\n",
       "      <td>482.840301</td>\n",
       "      <td>65.772316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.739435</td>\n",
       "      <td>{'datetime': '2022-12-09 22:20:17', 'elapsed':...</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>1.994299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>60.0</td>\n",
       "      <td>479.436874</td>\n",
       "      <td>37.916497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.739429</td>\n",
       "      <td>{'datetime': '2022-12-09 23:11:07', 'elapsed':...</td>\n",
       "      <td>0.631259</td>\n",
       "      <td>9.301112</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>70.0</td>\n",
       "      <td>849.415563</td>\n",
       "      <td>64.374209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.739332</td>\n",
       "      <td>{'datetime': '2022-12-09 20:45:12', 'elapsed':...</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>1.994299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>30.0</td>\n",
       "      <td>479.436874</td>\n",
       "      <td>37.916497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.738954</td>\n",
       "      <td>{'datetime': '2022-12-09 19:58:49', 'elapsed':...</td>\n",
       "      <td>0.577291</td>\n",
       "      <td>8.015872</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.055687</td>\n",
       "      <td>10.0</td>\n",
       "      <td>999.955914</td>\n",
       "      <td>80.915508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.738952</td>\n",
       "      <td>{'datetime': '2022-12-09 19:08:30', 'elapsed':...</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>1.994299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>10.0</td>\n",
       "      <td>479.436874</td>\n",
       "      <td>37.916497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                           datetime  \\\n",
       "21  0.740106  {'datetime': '2022-12-09 21:35:53', 'elapsed':...   \n",
       "3   0.740106  {'datetime': '2022-12-09 21:15:21', 'elapsed':...   \n",
       "14  0.740093  {'datetime': '2022-12-10 00:08:06', 'elapsed':...   \n",
       "24  0.740057  {'datetime': '2022-12-10 00:19:16', 'elapsed':...   \n",
       "24  0.739845  {'datetime': '2022-12-09 22:12:22', 'elapsed':...   \n",
       "10  0.739820  {'datetime': '2022-12-09 21:56:38', 'elapsed':...   \n",
       "0   0.739717  {'datetime': '2022-12-10 00:24:55', 'elapsed':...   \n",
       "3   0.739596  {'datetime': '2022-12-09 23:23:16', 'elapsed':...   \n",
       "21  0.739565  {'datetime': '2022-12-09 20:34:26', 'elapsed':...   \n",
       "23  0.739562  {'datetime': '2022-12-09 23:45:58', 'elapsed':...   \n",
       "17  0.739497  {'datetime': '2022-12-09 22:35:15', 'elapsed':...   \n",
       "13  0.739453  {'datetime': '2022-12-09 23:03:07', 'elapsed':...   \n",
       "17  0.739453  {'datetime': '2022-12-09 20:29:01', 'elapsed':...   \n",
       "20  0.739435  {'datetime': '2022-12-09 21:03:30', 'elapsed':...   \n",
       "3   0.739435  {'datetime': '2022-12-09 22:20:17', 'elapsed':...   \n",
       "21  0.739429  {'datetime': '2022-12-09 23:11:07', 'elapsed':...   \n",
       "3   0.739332  {'datetime': '2022-12-09 20:45:12', 'elapsed':...   \n",
       "20  0.738954  {'datetime': '2022-12-09 19:58:49', 'elapsed':...   \n",
       "3   0.738952  {'datetime': '2022-12-09 19:08:30', 'elapsed':...   \n",
       "\n",
       "    bagging_fraction  bagging_freq  batch_size  learning_rate  nFile  \\\n",
       "21          0.808382      3.260206        10.0       0.045185   40.0   \n",
       "3           0.663565      1.994299        10.0       0.094274   40.0   \n",
       "14          0.883442      9.491606        10.0       0.018799   90.0   \n",
       "24          0.317533      5.362842        10.0       0.079636   90.0   \n",
       "24          0.882175      2.103547        10.0       0.049750   50.0   \n",
       "10          0.702082      1.710437        10.0       0.088671   50.0   \n",
       "0           0.565568      9.522663        10.0       0.028957  100.0   \n",
       "3           0.663565      1.994299        10.0       0.094274   80.0   \n",
       "21          0.834545      9.822706        10.0       0.067652   20.0   \n",
       "23          0.976386      1.522631        10.0       0.075943   80.0   \n",
       "17          0.955275      2.466394        10.0       0.080818   60.0   \n",
       "13          0.959201      8.949202        10.0       0.089312   70.0   \n",
       "17          1.000000      1.000000        10.0       0.100000   20.0   \n",
       "20          0.922832      1.445393        10.0       0.080182   30.0   \n",
       "3           0.663565      1.994299        10.0       0.094274   60.0   \n",
       "21          0.631259      9.301112        10.0       0.039930   70.0   \n",
       "3           0.663565      1.994299        10.0       0.094274   30.0   \n",
       "20          0.577291      8.015872        10.0       0.055687   10.0   \n",
       "3           0.663565      1.994299        10.0       0.094274   10.0   \n",
       "\n",
       "    num_iterations  num_leaves  \n",
       "21      438.263273   45.704734  \n",
       "3       479.436874   37.916497  \n",
       "14      219.284683   93.503262  \n",
       "24      229.715740   96.115682  \n",
       "24      422.996505   62.278690  \n",
       "10      442.575021   46.245643  \n",
       "0       717.599877   20.878224  \n",
       "3       479.436874   37.916497  \n",
       "21      484.308256   89.495379  \n",
       "23      715.380881   56.672997  \n",
       "17      413.954070   60.979275  \n",
       "13      853.416132   62.844482  \n",
       "17      485.337529   49.965982  \n",
       "20      482.840301   65.772316  \n",
       "3       479.436874   37.916497  \n",
       "21      849.415563   64.374209  \n",
       "3       479.436874   37.916497  \n",
       "20      999.955914   80.915508  \n",
       "3       479.436874   37.916497  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "list_bayesOpt = glob.glob('../models/SVD/LightGBM_BayesOpt/logs_shuffle*.json')\n",
    "\n",
    "opt_best_df = pd.DataFrame()\n",
    "for jsonFile in list_bayesOpt:\n",
    "    with open(jsonFile) as f:\n",
    "        optList = []\n",
    "        for jsonObj in f:\n",
    "            optDict = json.loads(jsonObj)\n",
    "            optList.append(optDict)\n",
    "        \n",
    "        opt_df = pd.DataFrame(optList)\n",
    "        opt_df = pd.concat([opt_df.drop(['params'], axis=1), opt_df['params'].apply(pd.Series)], axis=1)\n",
    "        opt_best_df = pd.concat([opt_best_df,opt_df.sort_values('target',ascending=False).iloc[0:2]])\n",
    "\n",
    "opt_best_df.sort_values('target',ascending=False)\n",
    "# opt_df = pd.DataFrame(optList)\n",
    "# opt_df = pd.concat([opt_df.drop(['params'], axis=1), opt_df['params'].apply(pd.Series)], axis=1)\n",
    "# opt_df.sort_values('target',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851b1686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                0.739600\n",
       "bagging_fraction      0.754410\n",
       "bagging_freq          4.418216\n",
       "batch_size           10.000000\n",
       "learning_rate         0.072205\n",
       "nFile                52.631579\n",
       "num_iterations      534.327795\n",
       "num_leaves           57.122572\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_best_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86fcb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                0.739562\n",
       "bagging_fraction      0.702082\n",
       "bagging_freq          2.103547\n",
       "batch_size           10.000000\n",
       "learning_rate         0.080182\n",
       "nFile                50.000000\n",
       "num_iterations      479.436874\n",
       "num_leaves           56.672997\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_best_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff380d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(df_hist, df_lookup, sim_file_list, score_name_list):\n",
    "    df_hist['ListenYes'] = (df_hist['skip_2'] == False)*1\n",
    "    df_hist['ListenYes'].replace(0, -1, inplace = True)\n",
    "    df_hist = df_hist.groupby(['session_id', 'clus']).agg({'ListenYes':['sum']})\n",
    "    df_hist = df_hist.reset_index()\n",
    "    df_hist.columns = df_hist.columns.droplevel(level = 1) # take out the unwanted level\n",
    "    df_pivot = pd.pivot_table(df_hist, values = 'ListenYes',index='session_id', columns='clus')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    \n",
    "    for sim_file, score_name in zip(sim_file_list, score_name_list):\n",
    "        sim_matrix = pd.read_csv(sim_file).drop(columns=['Unnamed: 0'])\n",
    "        sim_matrix.columns = list(map(str, range(0,len(sim_matrix))))\n",
    "        df_sim_session = df_pivot.dot(sim_matrix)/sim_matrix.sum()\n",
    "        \n",
    "        df_lookup[score_name] = df_sim_session.lookup(df_lookup['session_id'],df_lookup['clus'].astype(str))\n",
    "    \n",
    "    return df_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc506af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for n in range(9):\n",
    "    file_list = file_list + glob.glob('../data/raw/training_set/log_'+str(n)+'*.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7358b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_FA = ['skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch','hour_of_day','premium',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hist_user_behavior_reason_end_backbtn',\n",
    "       'hist_user_behavior_reason_end_clickrow',\n",
    "       'hist_user_behavior_reason_end_endplay',\n",
    "       'hist_user_behavior_reason_end_fwdbtn',\n",
    "       'hist_user_behavior_reason_end_logout',\n",
    "       'hist_user_behavior_reason_end_remote',\n",
    "       'hist_user_behavior_reason_end_trackdone',\n",
    "       'hist_user_behavior_reason_start_appload',\n",
    "       'hist_user_behavior_reason_start_backbtn',\n",
    "       'hist_user_behavior_reason_start_clickrow',\n",
    "       'hist_user_behavior_reason_start_endplay',\n",
    "       'hist_user_behavior_reason_start_fwdbtn',\n",
    "       'hist_user_behavior_reason_start_playbtn',\n",
    "       'hist_user_behavior_reason_start_remote',\n",
    "       'hist_user_behavior_reason_start_trackdone',\n",
    "       'hist_user_behavior_reason_start_trackerror', 'context_type_catalog',\n",
    "       'context_type_charts', 'context_type_editorial_playlist',\n",
    "       'context_type_personalized_playlist', 'context_type_radio',\n",
    "       'context_type_user_collection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbde35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime per batch: 1257.38s\n",
      "Runtime per batch: 1116.35s\n",
      "Runtime per batch: 1311.74s\n",
      "Runtime per batch: 1366.48s\n",
      "Runtime per batch: 1274.30s\n",
      "Runtime per batch: 1293.05s\n",
      "Runtime per batch: 1517.06s\n",
      "Runtime per batch: 2278.90s\n",
      "Runtime per batch: 2680.02s\n",
      "Runtime per batch: 1501.70s\n",
      "Runtime per batch: 1490.85s\n",
      "Runtime per batch: 1509.07s\n",
      "Runtime per batch: 1644.65s\n",
      "Runtime per batch: 1726.37s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from timeit import default_timer as timer #to see how long the computation will take\n",
    "\n",
    "nFile = 220\n",
    "batch_size = 10\n",
    "while nFile < len(file_list):\n",
    "    start = timer()\n",
    "    nFile += batch_size\n",
    "    df_lookup_list = []\n",
    "    for file in file_list[(nFile-batch_size):min(nFile, len(file_list))]:\n",
    "       \n",
    "        log_df = pd.read_csv(file)\n",
    "        log_df = log_df.merge(kmean300_df)\n",
    "\n",
    "        log_df_1 = log_df.loc[log_df['session_position']<(log_df['session_length']/2)]\n",
    "        log_df_1['hour_of_day'] = log_df_1['hour_of_day'].astype('float')\n",
    "        log_df_1['premium'] = log_df_1['premium'].astype('bool')\n",
    "        log_df_1['weekday'] = log_df_1['date'].astype('datetime64[ns]').dt.dayofweek\n",
    "        log_df_1 = log_df_1.drop(columns = ['date'])\n",
    "        log_df_1 = pd.get_dummies(log_df_1, columns=['hist_user_behavior_reason_end', 'hist_user_behavior_reason_start', 'context_type'])\n",
    "        log_df_1_summary = log_df_1.groupby(['session_id'])[col_FA].agg(['mean'])\n",
    "        log_df_1_summary.columns = log_df_1_summary.columns.get_level_values(0)+'_'+log_df_1_summary.columns.get_level_values(1)\n",
    "        log_df_history = log_df_1[['session_id','track_id_clean','skip_2','clus']]\n",
    "\n",
    "\n",
    "        half_cut = log_df['session_length']/2\n",
    "\n",
    "        # need to at least include 2 trials, otherwise the log_df_1_summary will confound with all the tracks in the same session\n",
    "\n",
    "        #1st trial in the 2nd half\n",
    "        log_df_2_1 = log_df.loc[(log_df['session_position']>=half_cut) & (log_df['session_position']<half_cut+1)]\n",
    "        log_df_2_1 = log_df_2_1[['session_id','track_id_clean','skip_2','session_position','session_length','clus']]\n",
    "        log_df_2_1['weight'] = 1\n",
    "        \n",
    "        #2nd trial in the 2nd half\n",
    "        log_df_2_2 = log_df.loc[(log_df['session_position']>=half_cut+1) & (log_df['session_position']<half_cut+2)]\n",
    "        log_df_2_2 = log_df_2_2[['session_id','track_id_clean','skip_2','session_position','session_length','clus']]\n",
    "        log_df_2_2['weight'] = 0.5\n",
    "        \n",
    "        log_df_2 = pd.concat([log_df_2_1,log_df_2_2])\n",
    "        log_df_2 = log_df_2.merge(log_df_1_summary, on='session_id')\n",
    "\n",
    "\n",
    "        sim_file_list = ['../models/SVD/similarity/k300_CanbDist.csv',\n",
    "                         '../models/SVD/similarity/k300_CosSim.csv',\n",
    "                         '../models/SVD/similarity/k300_LinCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_ManhDist.csv',\n",
    "                         '../models/SVD/similarity/k300_HammDist.csv',\n",
    "                         '../models/SVD/similarity/k300_SpearCorr.csv',\n",
    "                         '../models/SVD/similarity/k300_KendCorr.csv']\n",
    "        score_name_list = ['CanbDist300', 'CosSim300','LinCorr300','ManhDist300','HammDist300','SpearCorr300','KendCorr300']\n",
    "\n",
    "        df_lookup_list.append(get_sim(log_df_history, log_df_2, sim_file_list, score_name_list))\n",
    "\n",
    "\n",
    "    df_lookup = pd.concat(df_lookup_list)\n",
    "    df_lookup = df_lookup.merge(tf_df)\n",
    "    df_lookup.drop(columns = ['key','time_signature','mode'], inplace = True)\n",
    "#     df_lookup = pd.get_dummies(df_lookup, columns=['key','time_signature','mode'])\n",
    "\n",
    "    dtrain = lgb.Dataset(df_lookup.drop(columns = ['session_id','track_id_clean','skip_2']), \n",
    "                         label=df_lookup['skip_2'],\n",
    "                         weight = df_lookup['weight'])\n",
    "    \n",
    "    params = {'num_leaves': 45,\n",
    "              'learning_rate':0.07,\n",
    "              'metric': 'binary_error',\n",
    "              'num_iterations':440,\n",
    "              'bagging_fraction':0.72,\n",
    "              'bagging_freq':3,\n",
    "              'objective': 'binary',\n",
    "              'force_row_wise': True,\n",
    "              'num_threads': 5,\n",
    "              'verbosity': 0,\n",
    "              'tree_learner': 'data'} #https://lightgbm.readthedocs.io/en/latest/Parallel-Learning-Guide.html\n",
    "    \n",
    "    if nFile == batch_size:\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=100)\n",
    "    else: # continue training on the previous model\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=100, init_model='../models/SVD/LightGBM_BayesOpt/LightGBM_incremental_training/boost'+str(int(nFile-batch_size))+'.txt')\n",
    "        \n",
    "    bst.save_model('../models/SVD/LightGBM_BayesOpt/LightGBM_incremental_training/boost'+str(int(nFile))+'.txt')\n",
    "\n",
    "    print('Runtime per batch: %0.2fs' % (timer() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2792e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af837e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
